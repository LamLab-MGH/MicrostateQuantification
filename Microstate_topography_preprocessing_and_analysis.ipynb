{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b6cf4f-9a1b-4c98-b06e-a1b1599f840c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Set calculation parameters if you are using Windows\n",
    "_original_omp_num_threads_ = None\n",
    "if sys.platform == 'win32':\n",
    "    _original_omp_num_threads_ = os.environ.get('OMP_NUM_THREADS')\n",
    "    os.environ['OMP_NUM_THREADS'] = '1'\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from scipy.spatial.distance import euclidean\n",
    "import pandas as pd\n",
    "from matplotlib.lines import Line2D\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis # For LDA\n",
    "\n",
    "def ep_read(filename):\n",
    "    \"\"\"\n",
    "    Read data from a Cartool .ep file.\n",
    "\n",
    "    This function reads a text file where each line contains space-separated\n",
    "    floating-point numbers. It skips any empty lines.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    filename : str\n",
    "        The path to the .ep file.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        A 2D NumPy array containing the data from the file.\n",
    "        Each row corresponds to a line in the file, and each column\n",
    "        corresponds to a number in that line.\n",
    "    \"\"\"\n",
    "    with open(filename, 'r') as file:\n",
    "        data = np.array([list(map(float, line.split())) for line in file if line.strip()])\n",
    "    return data\n",
    "\n",
    "def read_cartool_xyz(xyz_file):\n",
    "    \"\"\"\n",
    "    Read electrode positions and names from a Cartool .xyz file.\n",
    "\n",
    "    The Cartool .xyz file format typically starts with a header line\n",
    "    containing the number of electrodes. Subsequent lines contain\n",
    "    the X, Y, Z coordinates and the electrode name. \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    xyz_file : str\n",
    "        The path to the .xyz file.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    positions : numpy.ndarray\n",
    "        A 2D NumPy array of shape (n_electrodes, 3) containing the\n",
    "        X, Y, Z coordinates of each electrode after transformation.\n",
    "        Row 'i' corresponds to the coordinates of the i-th electrode.\n",
    "    ch_names : list of str\n",
    "        A list of strings, where each string is the name of an electrode.\n",
    "        The order of names corresponds to the rows in the 'positions' array.\n",
    "    \"\"\"\n",
    "    with open(xyz_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    header = lines[0].strip().split()\n",
    "    n_electrodes = int(header[0])\n",
    "    positions = np.zeros((n_electrodes, 3))\n",
    "    ch_names = []\n",
    "    for i in range(n_electrodes):\n",
    "        line = lines[i+1].strip().split()\n",
    "        positions[i, 0] = float(line[0])\n",
    "        positions[i, 1] = -float(line[1])\n",
    "        positions[i, 2] = float(line[2])\n",
    "        ch_names.append(line[3])\n",
    "    return positions, ch_names\n",
    "\n",
    "def plot_outliers(output_base_dir):\n",
    "    \"\"\"\n",
    "    Detect microstate topographic outliers defined by a Linear Discriminant Analysis (LDA) model trained \n",
    "    to separate outliers (High same class distance (SCD), Low different class distance (DCD) via medians) \n",
    "    from non-outliers (Low SCD, High DCD via medians).\n",
    "    \"\"\"\n",
    "\n",
    "    plt.rcParams.update({\n",
    "        'font.size': 18, 'axes.titlesize': 18, 'axes.labelsize': 18,\n",
    "        'xtick.labelsize': 18, 'ytick.labelsize': 18, 'legend.fontsize': 16\n",
    "    })\n",
    "\n",
    "    ms_labels_map = {0: 'A', 1: 'B', 2: 'C', 3: 'D'}\n",
    "    groups = ['HC', 'Young', 'ADNoEp', 'ADEp']\n",
    "    conditions = ['Awake', 'N2', 'REM']\n",
    "\n",
    "    results_dir = os.path.join(output_base_dir, f'outlier_plots_lda')\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "    all_outliers_dict = {}\n",
    "    all_non_outliers_dict = {}\n",
    "    all_data_list = []\n",
    "\n",
    "    for group in groups:\n",
    "        all_outliers_dict[group] = {}\n",
    "        all_non_outliers_dict[group] = {}\n",
    "        for condition in conditions:\n",
    "            input_dir = os.path.join(output_base_dir, f'{group}_{condition}_median')\n",
    "            plot_dir = os.path.join(results_dir, group)\n",
    "            os.makedirs(plot_dir, exist_ok=True)\n",
    "            print(f\"Processing {group} - {condition}...\")\n",
    "\n",
    "            if not os.path.exists(input_dir):\n",
    "                print(f\"  Directory not found: {input_dir}, skipping.\")\n",
    "                continue\n",
    "            subject_files = [f for f in os.listdir(input_dir)\n",
    "                             if f.startswith('Subject_') and f.endswith('_median_microstates.ep')]\n",
    "            if not subject_files:\n",
    "                print(f\"  No subject files found in {input_dir}, skipping.\")\n",
    "                continue\n",
    "            subject_data = {}\n",
    "            for filename in subject_files:\n",
    "                match = re.search(r'Subject_(\\d+)_median_microstates\\.ep', filename)\n",
    "                if not match: continue\n",
    "                subject_id = match.group(1)\n",
    "                file_path = os.path.join(input_dir, filename)\n",
    "                try:\n",
    "                    data_content = ep_read(file_path)\n",
    "                    if data_content.shape[0] == 4: subject_data[subject_id] = data_content\n",
    "                except Exception as e: print(f\"  Error reading {filename}: {e}\")\n",
    "            if not subject_data:\n",
    "                print(f\"  No valid subject data found for {group} - {condition}, skipping.\")\n",
    "                continue\n",
    "            \n",
    "            all_patterns = {ms_val: [] for ms_val in range(4)}\n",
    "            for subj_patterns in subject_data.values():\n",
    "                for ms_val in range(4): all_patterns[ms_val].append(subj_patterns[ms_val])\n",
    "            group_medians_reference = {}\n",
    "            for ms_val in range(4):\n",
    "                if all_patterns[ms_val]: group_medians_reference[ms_val] = np.median(np.array(all_patterns[ms_val]), axis=0)\n",
    "            \n",
    "            condition_records = []\n",
    "            for subject_id, patterns in subject_data.items():\n",
    "                for ms_class in range(4):\n",
    "                    if ms_class not in group_medians_reference: continue\n",
    "                    ms_label = ms_labels_map[ms_class]\n",
    "                    same_class_dist = euclidean(patterns[ms_class], group_medians_reference[ms_class])\n",
    "                    other_dists = [euclidean(patterns[ms_class], group_medians_reference[other_ms])\n",
    "                                   for other_ms in range(4) if other_ms != ms_class and other_ms in group_medians_reference]\n",
    "                    avg_other_dist = np.mean(other_dists) if other_dists else np.nan\n",
    "                    condition_records.append({\n",
    "                        'Group': group, 'Condition': condition, 'Subject ID': subject_id,\n",
    "                        'Microstate': ms_label, 'Same Class Distance': same_class_dist,\n",
    "                        'Diff Class Distance': avg_other_dist\n",
    "                    })\n",
    "            if not condition_records:\n",
    "                print(f\"  No records to process for {group} - {condition}.\")\n",
    "                continue\n",
    "            \n",
    "            df_condition = pd.DataFrame(condition_records)\n",
    "            df_condition.dropna(subset=['Same Class Distance', 'Diff Class Distance'], inplace=True)\n",
    "            \n",
    "            df_condition['Is Outlier'] = False # Default\n",
    "            median_scd_for_plot = np.nan\n",
    "            median_dcd_for_plot = np.nan\n",
    "            lda_model = None\n",
    "            scaler_model = None\n",
    "\n",
    "\n",
    "            if not df_condition.empty and len(df_condition) > 2: # Need enough points for medians and LDA\n",
    "                features_for_lda = df_condition[['Same Class Distance', 'Diff Class Distance']].values\n",
    "                scaler_model = StandardScaler()\n",
    "                scaled_features = scaler_model.fit_transform(features_for_lda)\n",
    "                \n",
    "                median_scd_for_plot = df_condition['Same Class Distance'].median()\n",
    "                median_dcd_for_plot = df_condition['Diff Class Distance'].median()\n",
    "\n",
    "                if pd.notna(median_scd_for_plot) and pd.notna(median_dcd_for_plot):\n",
    "    \n",
    "                    # Use original (unscaled) features for median comparison, then use scaled for LDA\n",
    "                    is_pno = (df_condition['Same Class Distance'] <= median_scd_for_plot) & \\\n",
    "                             (df_condition['Diff Class Distance'] >= median_dcd_for_plot)\n",
    "                    is_po = (df_condition['Same Class Distance'] > median_scd_for_plot) & \\\n",
    "                            (df_condition['Diff Class Distance'] < median_dcd_for_plot)\n",
    "                    \n",
    "                    # Select data for LDA training (only points in these two quadrants)\n",
    "                    lda_train_mask = is_pno | is_po\n",
    "                    X_lda_train = scaled_features[lda_train_mask]\n",
    "                    y_lda_train = np.zeros(len(df_condition)) # Temp array\n",
    "                    y_lda_train[is_pno] = 0 # Non-outlier class\n",
    "                    y_lda_train[is_po] = 1  # Outlier class\n",
    "                    y_lda_train = y_lda_train[lda_train_mask]\n",
    "\n",
    "                    if len(X_lda_train) > 0 and len(np.unique(y_lda_train)) == 2: # Need at least two classes for LDA\n",
    "                        try:\n",
    "                            lda_model = LinearDiscriminantAnalysis()\n",
    "                            lda_model.fit(X_lda_train, y_lda_train)\n",
    "                            \n",
    "                            # Predict on ALL scaled features\n",
    "                            all_predictions_lda = lda_model.predict(scaled_features)\n",
    "                            df_condition['Is Outlier'] = (all_predictions_lda == 1) # Label 1 was an outlier\n",
    "                            \n",
    "                            num_final_outliers = df_condition['Is Outlier'].sum()\n",
    "                            print(f\"  LDA trained on groups. Medians (SCD:{median_scd_for_plot:.2f}, DCD:{median_dcd_for_plot:.2f}). Found {num_final_outliers} final outliers.\")\n",
    "                        except Exception as e_lda:\n",
    "                            print(f\"  Error during LDA for {group} - {condition}: {e_lda}. No outliers assigned by LDA.\")\n",
    "                            df_condition['Is Outlier'] = False # Fallback\n",
    "                    else:\n",
    "                        print(f\"  Warning: Not enough data or only one class for LDA training in {group} - {condition} (PNO: {is_pno.sum()}, PO: {is_po.sum()}). Using simple median quadrant as fallback.\")\n",
    "                        # Fallback to simple median quadrant if LDA cannot be trained\n",
    "                        df_condition['Is Outlier'] = (df_condition['Same Class Distance'] > median_scd_for_plot) & \\\n",
    "                                                     (df_condition['Diff Class Distance'] < median_dcd_for_plot)\n",
    "                        num_fallback_outliers = df_condition['Is Outlier'].sum()\n",
    "                        print(f\"    Fallback to median quadrant: found {num_fallback_outliers} outliers.\")\n",
    "                        lda_model = None # Ensure no LDA line is plotted\n",
    "\n",
    "                else:\n",
    "                    print(f\"  Warning: Could not calculate SCD/DCD medians for {group} - {condition}. No outliers marked.\")\n",
    "            \n",
    "            elif df_condition.empty:\n",
    "                print(f\"  DataFrame empty for {group} - {condition} after NaN drop. No outliers.\")\n",
    "            else: # len(df_condition) <=2\n",
    "                print(f\"  Not enough data points ({len(df_condition)}) for LDA in {group} - {condition}. No outliers.\")\n",
    "\n",
    "\n",
    "            all_data_list.extend(df_condition.to_dict('records'))\n",
    "            condition_outliers = {ms_labels_map[ms_val]: [] for ms_val in range(4)}\n",
    "            condition_non_outliers = {ms_labels_map[ms_val]: [] for ms_val in range(4)}\n",
    "            for _, row in df_condition.iterrows():\n",
    "                if row.get('Is Outlier', False):\n",
    "                    condition_outliers[row['Microstate']].append(str(row['Subject ID']))\n",
    "                else:\n",
    "                    condition_non_outliers[row['Microstate']].append(str(row['Subject ID']))\n",
    "            all_outliers_dict[group][condition] = condition_outliers\n",
    "            all_non_outliers_dict[group][condition] = condition_non_outliers\n",
    "\n",
    "            if df_condition.empty:\n",
    "                continue\n",
    "            \n",
    "            plt.figure(figsize=(12, 12))\n",
    "            padding_factor = 1.1\n",
    "            x_data_max_val = df_condition['Same Class Distance'][np.isfinite(df_condition['Same Class Distance'])].max() if not df_condition['Same Class Distance'][np.isfinite(df_condition['Same Class Distance'])].empty else 0.0\n",
    "            y_data_max_val = df_condition['Diff Class Distance'][np.isfinite(df_condition['Diff Class Distance'])].max() if not df_condition['Diff Class Distance'][np.isfinite(df_condition['Diff Class Distance'])].empty else 0.0\n",
    "            base_max_for_scaling = max(x_data_max_val, y_data_max_val, 0.1) \n",
    "            \n",
    "            plot_xlim_upper = base_max_for_scaling * padding_factor\n",
    "            plot_ylim_upper = base_max_for_scaling * 2.0 * padding_factor \n",
    "            if plot_xlim_upper <=0: plot_xlim_upper = 1.0\n",
    "            if plot_ylim_upper <=0: plot_ylim_upper = 2.0\n",
    "\n",
    "            plt.xlim(0, plot_xlim_upper)\n",
    "            plt.ylim(0, plot_ylim_upper)\n",
    "            plt.axis('equal') \n",
    "            \n",
    "            final_xlims = plt.xlim()\n",
    "            final_ylims = plt.ylim()\n",
    "            # text_baseline_y_for_anno = final_ylims[0] + (final_ylims[1] - final_ylims[0]) * 0.01\n",
    "            # Select text baseline for arrow annotations\n",
    "            text_baseline_y_for_anno = 0.8\n",
    "\n",
    "            ms_colors_map = {'A': 'blue', 'B': 'green', 'C': 'orange', 'D': 'purple'}\n",
    "            legend_handles = [Line2D([0], [0], marker='o', color='w', markerfacecolor=col, markersize=8, label=f'MS {ms_lab}')\n",
    "                              for ms_lab, col in ms_colors_map.items()]\n",
    "            legend_handles.append(Line2D([0], [0], marker='o', color='w', markerfacecolor='gray', markersize=8, label='Non-outlier'))\n",
    "            legend_handles.append(Line2D([0], [0], marker='X', color='w', markerfacecolor='gray', markersize=8, markeredgecolor='red', label='Outlier (LDA-defined)'))\n",
    "\n",
    "            # Plot LDA decision boundary if model was successfully fit\n",
    "            if lda_model is not None and scaler_model is not None:\n",
    "                w = lda_model.coef_[0]\n",
    "                b = lda_model.intercept_[0]\n",
    "              \n",
    "                xx_line = np.linspace(final_xlims[0], final_xlims[1], 100)\n",
    "                if abs(w[1]) > 1e-6: # Avoid division by zero if w[1] is (close to) zero\n",
    "                    xx_line_scaled_x = (xx_line - scaler_model.mean_[0]) / scaler_model.scale_[0]\n",
    "                    yy_line_scaled_y = (-w[0] * xx_line_scaled_x - b) / w[1]\n",
    "                    yy_line = yy_line_scaled_y * scaler_model.scale_[1] + scaler_model.mean_[1]\n",
    "                    plt.plot(xx_line, yy_line, 'k-', linewidth=2, label='LDA Decision Boundary')\n",
    "                    legend_handles.append(Line2D([0], [0], linestyle='-', color='k', label='LDA Boundary'))\n",
    "                elif abs(w[0]) > 1e-6: # Vertical line: x_scaled = -b / w[0]\n",
    "                     x_boundary_val_scaled = -b / w[0]\n",
    "                     x_boundary_val = x_boundary_val_scaled * scaler_model.scale_[0] + scaler_model.mean_[0]\n",
    "                     plt.axvline(x_boundary_val, color='k', linestyle='-', linewidth=2, label='LDA Decision Boundary (Vertical)')\n",
    "                     legend_handles.append(Line2D([0], [0], linestyle='-', color='k', label='LDA Boundary'))\n",
    "\n",
    "\n",
    "            # Optionally, still plot median lines for reference if they were calculated\n",
    "            if pd.notna(median_scd_for_plot) and pd.notna(median_dcd_for_plot):\n",
    "                plt.axvline(median_scd_for_plot, color='grey', linestyle=':', linewidth=1, alpha=0.7, label=f'_MedSCD ({median_scd_for_plot:.2f})')\n",
    "                plt.axhline(median_dcd_for_plot, color='grey', linestyle=':', linewidth=1, alpha=0.7, label=f'_MedDCD ({median_dcd_for_plot:.2f})')\n",
    "                if not any(\"Median Info\" in h.get_label() for h in legend_handles if h.get_label()):\n",
    "                     legend_handles.append(Line2D([0], [0], linestyle=':', color='grey', label='Median Info'))\n",
    "\n",
    "\n",
    "            non_outlier_df = df_condition[~df_condition['Is Outlier']]\n",
    "\n",
    "            if not non_outlier_df.empty:\n",
    "                for ms_label_plot, color in ms_colors_map.items():\n",
    "                    plot_data = non_outlier_df[non_outlier_df['Microstate'] == ms_label_plot]\n",
    "                    if not plot_data.empty:\n",
    "                        plt.scatter(plot_data['Same Class Distance'], plot_data['Diff Class Distance'],\n",
    "                                    c=color, marker='o', s=60, alpha=0.7, zorder=2)\n",
    "            \n",
    "            outlier_df = df_condition[df_condition['Is Outlier']]\n",
    "            if not outlier_df.empty:\n",
    "                 for ms_label_plot, color in ms_colors_map.items():\n",
    "                    plot_data = outlier_df[outlier_df['Microstate'] == ms_label_plot]\n",
    "                    if not plot_data.empty:\n",
    "                        plt.scatter(plot_data['Same Class Distance'], plot_data['Diff Class Distance'],\n",
    "                                    facecolors=color, edgecolors='red', marker='X', s=100, linewidths=1.5, zorder=3)\n",
    "                        for _, row in plot_data.iterrows():\n",
    "                            x_coord, y_coord = row['Same Class Distance'], row['Diff Class Distance']\n",
    "                            if np.isnan(x_coord) or np.isnan(y_coord) or np.isinf(x_coord) or np.isinf(y_coord): continue\n",
    "                            text_x_coordinate = x_coord\n",
    "                            plt.annotate(\n",
    "                                f\"S{row['Subject ID']}({ms_label_plot})\", xy=(x_coord, y_coord),\n",
    "                                xytext=(text_x_coordinate, text_baseline_y_for_anno), fontsize=14, color='dimgray', zorder=5,\n",
    "                                ha='center', va='bottom', arrowprops=dict(arrowstyle=\"simple,head_length=0.3,head_width=0.3,tail_width=0.1\", linewidth=0.8, color='darkgray', shrinkA=2, shrinkB=2, connectionstyle=\"arc3,rad=0\"),\n",
    "                                bbox=dict(facecolor='white', alpha=0.6, edgecolor='lightgray', pad=0.2)\n",
    "                            )\n",
    "            \n",
    "            plt.xlabel('Distance to Same Class Median (SCD)')\n",
    "            plt.ylabel('Average Distance to Different Class Medians (DCD)')\n",
    "            plt.title(f'{group} - {condition}\\nOutliers defined by LDA')\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            \n",
    "            ordered_legend_handles = []\n",
    "\n",
    "            main_types = [h for h in legend_handles if \"MS \" in h.get_label()]\n",
    "            boundary_types = [h for h in legend_handles if \"Boundary\" in h.get_label() or \"Median Info\" in h.get_label()]\n",
    "            outlier_status = [h for h in legend_handles if \"outlier\" in h.get_label().lower()]\n",
    "            \n",
    "\n",
    "            final_legend_handles = [h for h in main_types + boundary_types + outlier_status if not h.get_label().startswith('_')]\n",
    "\n",
    "            plt.legend(handles=final_legend_handles, loc='best', fontsize=12)\n",
    "\n",
    "            try:\n",
    "                plt.tight_layout(pad=0.3)\n",
    "            except UserWarning:\n",
    "                print(f\"  Note: Tight layout could not be fully applied for plot {group} - {condition}.\")\n",
    "            plt.savefig(os.path.join(plot_dir, f'{group}_{condition}_ALL_MS_lda_median_outlier_plot.png'), dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "            print(f\"  Created LDA-based outlier plot for {group} - {condition}\")\n",
    "            \n",
    "\n",
    "    if all_data_list:\n",
    "        all_df = pd.DataFrame(all_data_list)\n",
    "        csv_filename = f'all_microstate_distance_data_lda_median.csv' # Update filename\n",
    "        all_df.to_csv(os.path.join(results_dir, csv_filename), index=False)\n",
    "        summary_data = []\n",
    "        for group_s in groups:\n",
    "            if group_s not in all_outliers_dict: continue\n",
    "            for condition_s in conditions:\n",
    "                if condition_s not in all_outliers_dict[group_s]: continue\n",
    "                for ms_label_s in ms_labels_map.values():\n",
    "                    subset = all_df[(all_df['Group'] == group_s) & (all_df['Condition'] == condition_s) & (all_df['Microstate'] == ms_label_s)]\n",
    "                    if subset.empty:\n",
    "                        summary_data.append({'Group': group_s, 'Condition': condition_s, 'Microstate': ms_label_s, 'Total Subjects': 0, 'Outliers': 0, 'Non-outliers': 0, 'Outlier Percentage': 0})\n",
    "                        continue\n",
    "                    total = len(subset)\n",
    "                    outlier_col = subset.get('Is Outlier', pd.Series(False, index=subset.index, dtype=bool))\n",
    "                    outlier_count = outlier_col.sum() if pd.api.types.is_bool_dtype(outlier_col) else 0\n",
    "                    non_outlier_count = total - outlier_count\n",
    "                    summary_data.append({'Group': group_s, 'Condition': condition_s, 'Microstate': ms_label_s, 'Total Subjects': total, 'Outliers': outlier_count, 'Non-outliers': non_outlier_count, 'Outlier Percentage': round(outlier_count/total*100, 1) if total > 0 else 0})\n",
    "        if summary_data:\n",
    "            summary_df = pd.DataFrame(summary_data)\n",
    "            summary_csv_filename = f'outlier_summary_lda.csv' # Update filename\n",
    "            summary_df.to_csv(os.path.join(results_dir, summary_csv_filename), index=False)\n",
    "            print(f\"Saved LDA-based summary statistics to {os.path.join(results_dir, summary_csv_filename)}\")\n",
    "\n",
    "    print(f\"2D microstate outlier assessment with LDA complete.\")\n",
    "    return all_outliers_dict, all_non_outliers_dict\n",
    "\n",
    "# Call the function to load the median microstates for each subject and detect microstate outliers for each subject\n",
    "output_base_dir = './median_microstates_and_outliers'\n",
    "if not os.path.exists(output_base_dir):\n",
    "    print(f\"Error: Base directory for input data '{output_base_dir}' not found.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "outliers, non_outliers = plot_outliers(output_base_dir)\n",
    "\n",
    "no_outliers_found_overall = True\n",
    "if outliers:\n",
    "    for group_name, conditions_data in outliers.items():\n",
    "        for condition_name, ms_data in conditions_data.items():\n",
    "            for ms_label_name, subject_ids in ms_data.items():\n",
    "                if subject_ids:\n",
    "                    print(f\"Group: {group_name}, Condition: {condition_name}, MS: {ms_label_name}, Outliers: {subject_ids}\")\n",
    "                    no_outliers_found_overall = False\n",
    "if no_outliers_found_overall:\n",
    "    print(f\"No outliers identified with the LDA-based criteria and current data.\")\n",
    "\n",
    "# Restore calculation parameters if you are using Windows\n",
    "if sys.platform == 'win32':\n",
    "    if _original_omp_num_threads_ is None:\n",
    "        if 'OMP_NUM_THREADS' in os.environ:\n",
    "            del os.environ['OMP_NUM_THREADS']\n",
    "    else:\n",
    "        os.environ['OMP_NUM_THREADS'] = _original_omp_num_threads_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f407ea-d94b-4926-8167-bad7fe1b7586",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from scipy.stats import ttest_ind\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import matplotlib.colors as mcolors\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import math\n",
    "import re\n",
    "\n",
    "# --- GLOBAL CONSTANTS ---\n",
    "ms_labels = {0: 'A', 1: 'B', 2: 'C', 3: 'D'}\n",
    "\n",
    "def cohen_d(x, y):\n",
    "    \"\"\"\n",
    "    Calculates Cohen's d for independent samples.\n",
    "    \"\"\"\n",
    "    nx = len(x)\n",
    "    ny = len(y)\n",
    "    if nx < 1 or ny < 1:\n",
    "        return np.nan\n",
    "    mx = np.mean(x)\n",
    "    my = np.mean(y)\n",
    "    sx = np.std(x, ddof=1) if nx > 1 else 0\n",
    "    sy = np.std(y, ddof=1) if ny > 1 else 0\n",
    "\n",
    "    if (nx <= 1 and ny <= 1) or (sx == 0 and sy == 0):\n",
    "        return 0.0 if mx == my else np.inf\n",
    "\n",
    "    pooled_sd = np.sqrt(((nx - 1) * sx**2 + (ny - 1) * sy**2) / (nx + ny - 2))\n",
    "\n",
    "    return (mx - my) / pooled_sd if pooled_sd != 0 else (0.0 if mx == my else np.inf)\n",
    "\n",
    "\n",
    "def draw_head(ax):\n",
    "    \"\"\"Draws a standard head schematic.\"\"\"\n",
    "    head_radius = 1.0\n",
    "    circ = plt.Circle((0, 0), radius=head_radius, color='k', fill=False, lw=1.5, clip_on=False, zorder=1)\n",
    "    ax.add_patch(circ)\n",
    "    ax.plot([0, 0], [head_radius, head_radius * 1.1], color='k', lw=1.5, clip_on=False, zorder=1)\n",
    "    ear_y_offset = 0.0; ear_x_pos = head_radius * 0.98\n",
    "    ear_length_scale = 0.12; ear_angle_scale=0.15\n",
    "    ax.plot([-ear_x_pos, -ear_x_pos - ear_length_scale*head_radius], [ear_y_offset, ear_y_offset + ear_angle_scale*head_radius], color='k', lw=1.0, clip_on=False, zorder=1)\n",
    "    ax.plot([ear_x_pos, ear_x_pos + ear_length_scale*head_radius], [ear_y_offset, ear_y_offset + ear_angle_scale*head_radius], color='k', lw=1.0, clip_on=False, zorder=1)\n",
    "    ax.set_aspect('equal'); ax.set_xlim(-head_radius * 1.3, head_radius * 1.3); ax.set_ylim(-head_radius * 1.3, head_radius * 1.3); ax.axis('off')\n",
    "\n",
    "def plot_channel_values(\n",
    "    ax, p2d_standard_coords, values, cmap, vmin, vmax, default_size=150,\n",
    "    sig_mask=None, size_values=None, size_vmin=0.0, size_vmax=1.0,\n",
    "    min_marker_size=50, max_marker_size=600):\n",
    "    \"\"\"Plots channels as colored circles with optional size mapping.\"\"\"\n",
    "    if p2d_standard_coords is None or not isinstance(p2d_standard_coords, np.ndarray) or p2d_standard_coords.ndim != 2 or p2d_standard_coords.shape[1]!=2:\n",
    "        return None\n",
    "    if values is None or len(values) != p2d_standard_coords.shape[0]:\n",
    "        return None\n",
    "\n",
    "    norm = mcolors.Normalize(vmin=vmin, vmax=vmax)\n",
    "    if sig_mask is None or len(sig_mask) != len(values): sig_mask = np.ones(len(values), dtype=bool)\n",
    "\n",
    "    valid_idx = np.where(~np.isnan(values) & sig_mask)[0]\n",
    "    if len(valid_idx) == 0: return None\n",
    "\n",
    "    plot_x = p2d_standard_coords[valid_idx, 0]\n",
    "    plot_y = p2d_standard_coords[valid_idx, 1]\n",
    "\n",
    "    scatter_sizes_arr = np.full(len(valid_idx), default_size, dtype=float)\n",
    "    if size_values is not None and len(size_values) == len(values):\n",
    "        valid_size_vals_indexed = size_values[valid_idx]\n",
    "        size_range_val = size_vmax - size_vmin\n",
    "        if size_range_val <= 1e-9: size_range_val = 1.0\n",
    "        normalized_s_vals = np.clip((np.nan_to_num(valid_size_vals_indexed, nan=size_vmin) - size_vmin) / size_range_val, 0, 1)\n",
    "        calculated_s_arr = min_marker_size + (max_marker_size - min_marker_size) * normalized_s_vals\n",
    "        scatter_sizes_arr = np.maximum(calculated_s_arr, 1)\n",
    "        if len(scatter_sizes_arr) != len(valid_idx):\n",
    "            scatter_sizes_arr = np.full(len(valid_idx), default_size, dtype=float)\n",
    "\n",
    "    try:\n",
    "        sc = ax.scatter(plot_x, plot_y, c=values[valid_idx], cmap=cmap, norm=norm,\n",
    "                        edgecolors='k', linewidths=0.5, s=scatter_sizes_arr, marker='o', zorder=3)\n",
    "        return sc\n",
    "    except Exception as e_scatter:\n",
    "        print(f\"Error during scatter plot: {e_scatter}\")\n",
    "        return None\n",
    "\n",
    "def compare_median_microstates_across_conditions(\n",
    "    ref_path,\n",
    "    other_paths,\n",
    "    output_base,\n",
    "    xyz_file=None,\n",
    "    exclude_outliers=False,\n",
    "    outlier_subjects=None, \n",
    "    output_suffix=''\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Compares median microstate maps across different conditions.\n",
    "\n",
    "    This function loads median microstate maps for a reference condition and\n",
    "    one or more other conditions, performs channel-wise statistical comparisons\n",
    "    (independent samples t-tests), applies FDR correction for multiple\n",
    "    comparisons, and generates visualizations and summary reports.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ref_path : str\n",
    "        Path to the directory containing median microstate .ep files for the\n",
    "        reference condition. Files should be named like 'Subject_<ID>_median_microstates.ep'.\n",
    "    other_paths : dict\n",
    "        A dictionary where keys are condition names (e.g., 'ConditionA') and\n",
    "        values are paths to directories containing median microstate .ep files\n",
    "        for those conditions. File naming convention should be the same as for\n",
    "        `ref_path`.\n",
    "    output_base : str\n",
    "        Base path for the output directory where results (plots, CSVs, reports)\n",
    "        will be saved. Subdirectories for each comparison pair will be created\n",
    "        under this base path.\n",
    "    xyz_file : str, optional\n",
    "        Path to a Cartool .xyz electrode coordinates file. If provided and valid,\n",
    "        electrode positions will be used for plotting. If None or the file is\n",
    "        not found/invalid, plotting will be disabled.\n",
    "    exclude_outliers : bool, default False\n",
    "        If True, subjects identified as outliers (based on `outlier_subjects`)\n",
    "        will be excluded from the statistical comparisons and group averages\n",
    "        on a microstate-specific basis.\n",
    "    outlier_subjects : dict, optional\n",
    "        A nested dictionary specifying outlier subjects for each condition and\n",
    "        microstate. The structure should be:\n",
    "        `{'Group1': {'ConditionA': {'MS_A': ['subj1', 'subj2'], 'MS_B': [...]}, ...}, ...}`\n",
    "        where 'Group1' might be parsed from the condition key, and 'MS_A', 'MS_B'\n",
    "        are microstate labels (e.g., 'A', 'B', 'C', 'D'). This is only used if\n",
    "        `exclude_outliers` is True.\n",
    "    output_suffix : str, default ''\n",
    "        A suffix to add to the output directory names, filenames (plots, CSVs,\n",
    "        reports).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        A nested dictionary containing the results of the statistical comparisons\n",
    "        for each pair of conditions and each microstate. The structure is:\n",
    "        `{(condition1, condition2): {ms_index: {'raw_p_values': ..., 'z_mean_diffs': ..., ...}, ...}, ...}`\n",
    "        where `ms_index` is 0-3 representing microstates A, B, C, D respectively.\n",
    "        Returns None if no data is successfully loaded or if there are not enough\n",
    "        conditions for comparison.\n",
    "    \"\"\"\n",
    "    # Set a fixed random seed for reproducibility\n",
    "    np.random.seed(42)\n",
    "\n",
    "    # Prepare output directory path based on whether outliers are excluded\n",
    "    if exclude_outliers:\n",
    "        actual_suffix = output_suffix if output_suffix else \"_ms_excluded\"\n",
    "        output_base_analysis = f\"{output_base}{actual_suffix}\"\n",
    "        print(f\"\\nINFO: Running analysis with MICROSTATE-WISE outlier exclusion. Results: {output_base_analysis}\")\n",
    "    else:\n",
    "        output_base_analysis = output_base\n",
    "        print(f\"\\nINFO: Running analysis with all subjects/microstates. Results: {output_base_analysis}\")\n",
    "    os.makedirs(output_base_analysis, exist_ok=True)\n",
    "\n",
    "    # Load electrode coordinates for topographic plotting if available\n",
    "    pos_xyz_coords = None; ch_names_from_xyz_file = None; p2d_normalized_coords = None\n",
    "    if xyz_file and os.path.exists(xyz_file):\n",
    "        try:\n",
    "            # Attempt to read electrode positions from XYZ file\n",
    "            pos_xyz_coords, ch_names_from_xyz_file = read_cartool_xyz(xyz_file)\n",
    "            print(f\"  Loaded {len(ch_names_from_xyz_file)} electrode positions from {xyz_file}.\")\n",
    "            \n",
    "            # Validate the electrode data format\n",
    "            if not (isinstance(pos_xyz_coords, np.ndarray) and pos_xyz_coords.ndim == 2 and pos_xyz_coords.shape[1] == 3 and\n",
    "                    isinstance(ch_names_from_xyz_file, list) and len(ch_names_from_xyz_file) == pos_xyz_coords.shape[0]):\n",
    "                raise ValueError(\"XYZ file data format incorrect.\")\n",
    "        except Exception as e:\n",
    "            # Disable plotting if electrode file loading fails\n",
    "            print(f\"  Error loading/validating electrode file '{xyz_file}': {e}. Plotting disabled.\")\n",
    "            pos_xyz_coords = None\n",
    "    else:\n",
    "        print(f\"  Electrode file ({xyz_file}) not provided or not found. Plotting disabled.\")\n",
    "\n",
    "    # Extract condition name from reference path and create a dictionary of all conditions\n",
    "    try: \n",
    "        ref_name_key_main = os.path.basename(ref_path.rstrip(os.sep)).replace('_median', '')\n",
    "    except Exception: \n",
    "        ref_name_key_main = \"Reference\"\n",
    "    \n",
    "    # Combine reference and other conditions into a single dictionary for processing\n",
    "    conditions_to_load_paths_main = {ref_name_key_main: ref_path}\n",
    "    conditions_to_load_paths_main.update(other_paths)\n",
    "    print(f\"\\nConditions to be processed: {list(conditions_to_load_paths_main.keys())}\")\n",
    "\n",
    "    # Initialize storage for condition data and subject counts\n",
    "    condition_data_store = {}\n",
    "    n_channels_global_val = None\n",
    "    initial_subject_counts_dict = {}\n",
    "\n",
    "    # Define known group and condition names for parsing condition keys\n",
    "    known_groups_for_parse = ['HC', 'Young', 'ADNoEp', 'ADEp']\n",
    "    known_conditions_short_parse = ['Awake', 'N2', 'REM']\n",
    "\n",
    "    # Load data for each condition\n",
    "    for cond_key_main, data_folder_path_main in conditions_to_load_paths_main.items():\n",
    "        print(f\"\\nLoading data for condition key: {cond_key_main} from path: {data_folder_path_main}\")\n",
    "        initial_subject_counts_dict[cond_key_main] = {'found_files': 0, 'loaded_subjects': 0}\n",
    "        \n",
    "        # Attempt to list files in the condition directory\n",
    "        try: \n",
    "            files_in_folder_main = os.listdir(data_folder_path_main)\n",
    "        except FileNotFoundError: \n",
    "            print(f\"  Error: Directory not found: {data_folder_path_main}. Skipping.\")\n",
    "            continue\n",
    "        \n",
    "        # Filter for subject median microstate files\n",
    "        subject_ep_files_main = sorted([f for f in files_in_folder_main if f.startswith('Subject_') and f.endswith('_median_microstates.ep')])\n",
    "        initial_subject_counts_dict[cond_key_main]['found_files'] = len(subject_ep_files_main)\n",
    "        \n",
    "        if not subject_ep_files_main: \n",
    "            print(f\"  No subject median files found for {cond_key_main}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Storage for subject data in this condition\n",
    "        current_cond_subj_data_main = []\n",
    "        \n",
    "        # Try to parse group and condition from condition key for outlier handling\n",
    "        parsed_g_main, parsed_c_main = None, None\n",
    "        key_parts_main = cond_key_main.split('_')\n",
    "        if len(key_parts_main) >= 2:\n",
    "            potential_g_main = key_parts_main[0]\n",
    "            potential_c_short_main = key_parts_main[-1]\n",
    "            if potential_g_main in known_groups_for_parse and potential_c_short_main in known_conditions_short_parse:\n",
    "                parsed_g_main, parsed_c_main = potential_g_main, potential_c_short_main\n",
    "            elif len(key_parts_main) > 1:\n",
    "                joined_group_candidate_main = \"_\".join(key_parts_main[:-1])\n",
    "                if joined_group_candidate_main in known_groups_for_parse and potential_c_short_main in known_conditions_short_parse:\n",
    "                    parsed_g_main, parsed_c_main = joined_group_candidate_main, potential_c_short_main\n",
    "        \n",
    "        if not (parsed_g_main and parsed_c_main):\n",
    "            print(f\"  Warning: Could not parse Group/Condition from key '{cond_key_main}'. Outlier exclusion depends on matching keys in 'outlier_subjects'.\")\n",
    "\n",
    "        # Process each subject's median microstate file\n",
    "        for ep_filename_main in tqdm(subject_ep_files_main, desc=f\"  Loading {cond_key_main}\", unit=\"file\", leave=False):\n",
    "            full_fpath_main = os.path.join(data_folder_path_main, ep_filename_main)\n",
    "            \n",
    "            # Extract subject ID from filename\n",
    "            id_match_main = re.search(r'Subject_(\\d+)_median_microstates\\.ep', ep_filename_main)\n",
    "            if not id_match_main: \n",
    "                continue\n",
    "                \n",
    "            subj_id_main = id_match_main.group(1)\n",
    "            \n",
    "            try:\n",
    "                # Read the microstate map from .ep file\n",
    "                subj_ms_map_main = ep_read(full_fpath_main)\n",
    "                \n",
    "                # Validate microstate map format (should be 4 microstates)\n",
    "                if not (isinstance(subj_ms_map_main, np.ndarray) and subj_ms_map_main.ndim == 2 and subj_ms_map_main.shape[0] == 4):\n",
    "                    print(f\"  Warn: Invalid map format or not 4 MS for {subj_id_main} in {ep_filename_main}. Skip.\")\n",
    "                    continue\n",
    "                    \n",
    "                # Check channel count consistency\n",
    "                current_n_ch_main = subj_ms_map_main.shape[1]\n",
    "                if n_channels_global_val is None: \n",
    "                    n_channels_global_val = current_n_ch_main\n",
    "                elif current_n_ch_main != n_channels_global_val: \n",
    "                    print(f\"  Warn: Chan count mismatch for {subj_id_main} in {ep_filename_main}. Skip.\")\n",
    "                    continue\n",
    "                \n",
    "                # Calculate z-score maps for each microstate\n",
    "                subj_zmap_main = np.zeros_like(subj_ms_map_main)\n",
    "                for i_ms_main in range(4):\n",
    "                    row_data_main = subj_ms_map_main[i_ms_main,:]\n",
    "                    mean_val_main = np.nanmean(row_data_main)\n",
    "                    std_val_main = np.nanstd(row_data_main)\n",
    "                    # Avoid division by zero when calculating z-scores\n",
    "                    subj_zmap_main[i_ms_main,:] = (row_data_main - mean_val_main) / std_val_main if std_val_main > 1e-10 else np.zeros_like(row_data_main)\n",
    "                \n",
    "                # Store the subject's data\n",
    "                current_cond_subj_data_main.append({'id': subj_id_main, 'map': subj_ms_map_main, 'zmap': subj_zmap_main})\n",
    "            \n",
    "            except Exception as e_load_main: \n",
    "                print(f\"  Error processing file {ep_filename_main} for subject {subj_id_main}: {e_load_main}. Skip.\")\n",
    "\n",
    "        # Check if any valid data was loaded for this condition\n",
    "        if not current_cond_subj_data_main: \n",
    "            print(f\"  No valid subject data loaded for {cond_key_main}. Skipping.\")\n",
    "            continue\n",
    "            \n",
    "        # Update subject count and store condition data\n",
    "        initial_subject_counts_dict[cond_key_main]['loaded_subjects'] = len(current_cond_subj_data_main)\n",
    "        print(f\"  Loaded data for {len(current_cond_subj_data_main)} subjects for {cond_key_main}.\")\n",
    "        condition_data_store[cond_key_main] = {\n",
    "            'subject_data': current_cond_subj_data_main,\n",
    "            'parsed_group': parsed_g_main, 'parsed_condition': parsed_c_main\n",
    "        }\n",
    "\n",
    "    # Check if any data was successfully loaded\n",
    "    if n_channels_global_val is None: \n",
    "        print(\"\\nFATAL Error: No data successfully loaded, channel count undetermined.\")\n",
    "        return None\n",
    "        \n",
    "    # Set channel count and default channel names\n",
    "    n_channels_final = n_channels_global_val\n",
    "    master_channel_names = [f'Ch{i+1}' for i in range(n_channels_final)]\n",
    "\n",
    "    # Process electrode coordinates for plotting if available\n",
    "    if pos_xyz_coords is not None:\n",
    "        # Check if electrode count matches data channel count\n",
    "        if len(ch_names_from_xyz_file) != n_channels_final:\n",
    "            print(f\"  Warning: Electrode file channel names ({len(ch_names_from_xyz_file)}) count mismatch with data channels ({n_channels_final}). Plotting disabled.\")\n",
    "            p2d_normalized_coords = None\n",
    "        else:\n",
    "            # Use electrode names from file instead of default channel names\n",
    "            master_channel_names = ch_names_from_xyz_file\n",
    "            try:\n",
    "                # Convert 3D coordinates to 2D for plotting (using x,y coordinates)\n",
    "                coords_for_plot_2d_final = np.stack((pos_xyz_coords[:,1], pos_xyz_coords[:,0]), axis=-1)\n",
    "                \n",
    "                # Normalize coordinates to fit in plotting area\n",
    "                max_abs_coord_val = np.max(np.abs(coords_for_plot_2d_final))\n",
    "                p2d_normalized_coords = coords_for_plot_2d_final / max_abs_coord_val if max_abs_coord_val > 1e-9 else coords_for_plot_2d_final\n",
    "                print(\"  Electrode positions processed and normalized for plotting.\")\n",
    "            except Exception as e_pos_final_proc:\n",
    "                print(f\"  Error processing electrode positions for 2D norm: {e_pos_final_proc}. Plotting disabled.\")\n",
    "                p2d_normalized_coords = None\n",
    "\n",
    "    # Calculate group average maps for each condition, with outlier exclusion if specified\n",
    "    condition_processed_avg_maps_dict = {}\n",
    "    print(\"\\nCalculating group averages (MS-wise exclusion if active)...\")\n",
    "    for cond_key_avg_main, data_payload_main in condition_data_store.items():\n",
    "        # Get parsed group and condition for this condition\n",
    "        pg_avg = data_payload_main['parsed_group']\n",
    "        pc_avg = data_payload_main['parsed_condition']\n",
    "        \n",
    "        # Initialize empty average maps\n",
    "        avg_raw_map = np.full((4, n_channels_final), np.nan)\n",
    "        avg_z_map = np.full((4, n_channels_final), np.nan)\n",
    "        n_raw_ms = [0]*4\n",
    "        n_z_ms = [0]*4\n",
    "        \n",
    "        # Calculate average for each microstate\n",
    "        for ms_i_avg in range(4):\n",
    "            ms_l_avg = ms_labels[ms_i_avg]  # Convert microstate index to label (A, B, C, D)\n",
    "            valid_r_maps = []\n",
    "            valid_z_maps = []\n",
    "            \n",
    "            # Process each subject, checking for outliers\n",
    "            for s_dat_avg in data_payload_main['subject_data']:\n",
    "                is_o_avg = False\n",
    "                \n",
    "                # Check if subject is an outlier for this microstate\n",
    "                if exclude_outliers and outlier_subjects and pg_avg and pc_avg and \\\n",
    "                   pg_avg in outlier_subjects and pc_avg in outlier_subjects[pg_avg] and \\\n",
    "                   ms_l_avg in outlier_subjects[pg_avg][pc_avg]:\n",
    "                    if s_dat_avg['id'] in outlier_subjects[pg_avg][pc_avg][ms_l_avg]: \n",
    "                        is_o_avg = True\n",
    "                \n",
    "                # If not an outlier, include in average calculation\n",
    "                if not is_o_avg:\n",
    "                    valid_r_maps.append(s_dat_avg['map'][ms_i_avg, :])\n",
    "                    valid_z_maps.append(s_dat_avg['zmap'][ms_i_avg, :])\n",
    "            \n",
    "            # Calculate averages if there are valid maps\n",
    "            if valid_r_maps: \n",
    "                avg_raw_map[ms_i_avg,:] = np.mean(valid_r_maps, axis=0)\n",
    "                n_raw_ms[ms_i_avg] = len(valid_r_maps)\n",
    "            if valid_z_maps: \n",
    "                avg_z_map[ms_i_avg,:] = np.mean(valid_z_maps, axis=0)\n",
    "                n_z_ms[ms_i_avg] = len(valid_z_maps)\n",
    "        \n",
    "        # Store average maps and subject counts\n",
    "        condition_processed_avg_maps_dict[cond_key_avg_main] = {\n",
    "            'raw_average': avg_raw_map, 'z_average': avg_z_map,\n",
    "            'n_per_ms_raw': n_raw_ms, 'n_per_ms_z': n_z_ms\n",
    "        }\n",
    "\n",
    "    # Check that reference condition data exists and there are enough conditions for comparison\n",
    "    if ref_name_key_main not in condition_data_store or len(condition_data_store) < 2:\n",
    "        print(f\"\\nError: Ref condition '{ref_name_key_main}' data missing or not enough conditions. Cannot proceed.\")\n",
    "        return None\n",
    "\n",
    "    # Create comparison pairs: \n",
    "    # 1. Reference vs each other condition\n",
    "    # 2. All pairwise comparisons between other conditions\n",
    "    comparison_pairs_final_list = []\n",
    "    available_conds_comp_final = list(condition_data_store.keys())\n",
    "    other_conds_comp_final = [c for c in available_conds_comp_final if c != ref_name_key_main]\n",
    "    \n",
    "    # Add reference vs each other condition\n",
    "    for oc_final in other_conds_comp_final: \n",
    "        comparison_pairs_final_list.append((ref_name_key_main, oc_final))\n",
    "    \n",
    "    # Add pairwise comparisons between other conditions\n",
    "    for i_oc1_final in range(len(other_conds_comp_final)):\n",
    "        for i_oc2_final in range(i_oc1_final + 1, len(other_conds_comp_final)):\n",
    "            comparison_pairs_final_list.append((other_conds_comp_final[i_oc1_final], other_conds_comp_final[i_oc2_final]))\n",
    "    \n",
    "    if not comparison_pairs_final_list: \n",
    "        print(\"\\nError: No valid comparison pairs formed.\")\n",
    "        return None\n",
    "        \n",
    "    print(f\"\\nComparison pairs for stats: {comparison_pairs_final_list}\")\n",
    "\n",
    "    # Helper function to get microstate data for statistical testing\n",
    "    def get_data_for_stat_testing_internal(target_key_stat, ms_idx_for_stat, map_type_for_stat):\n",
    "        \"\"\"\n",
    "        Extract data for a specific microstate and condition, applying outlier exclusion if needed.\n",
    "        \n",
    "        Parameters:\n",
    "        - target_key_stat: Condition key to retrieve data for\n",
    "        - ms_idx_for_stat: Microstate index (0-3)\n",
    "        - map_type_for_stat: Map type ('map' for raw or 'zmap' for z-score)\n",
    "        \n",
    "        Returns:\n",
    "        - Array of maps (subjects x channels) for the specified microstate\n",
    "        \"\"\"\n",
    "        ms_lab_for_stat = ms_labels[ms_idx_for_stat]\n",
    "        lookup_info_stat = condition_data_store.get(target_key_stat)\n",
    "        if not lookup_info_stat: \n",
    "            return np.array([])\n",
    "            \n",
    "        pg_for_stat, pc_for_stat = lookup_info_stat['parsed_group'], lookup_info_stat['parsed_condition']\n",
    "        maps_for_stat_list = []\n",
    "        \n",
    "        for s_info_for_stat in lookup_info_stat['subject_data']:\n",
    "            s_id_for_stat, is_o_for_stat = s_info_for_stat['id'], False\n",
    "            \n",
    "            # Check if subject is an outlier for this microstate\n",
    "            if exclude_outliers and outlier_subjects and pg_for_stat and pc_for_stat and \\\n",
    "               pg_for_stat in outlier_subjects and pc_for_stat in outlier_subjects[pg_for_stat] and \\\n",
    "               ms_lab_for_stat in outlier_subjects[pg_for_stat][pc_for_stat]:\n",
    "                if s_id_for_stat in outlier_subjects[pg_for_stat][pc_for_stat][ms_lab_for_stat]: \n",
    "                    is_o_for_stat = True\n",
    "            \n",
    "            # If not an outlier, include in statistical testing\n",
    "            if not is_o_for_stat:\n",
    "                if map_type_for_stat in s_info_for_stat and ms_idx_for_stat < s_info_for_stat[map_type_for_stat].shape[0]:\n",
    "                    maps_for_stat_list.append(s_info_for_stat[map_type_for_stat][ms_idx_for_stat, :])\n",
    "        \n",
    "        return np.array(maps_for_stat_list)\n",
    "\n",
    "    # Perform statistical comparisons between condition pairs\n",
    "    all_comparison_results_dict = {}\n",
    "    print(f\"\\nRunning channel-wise stats (MS-wise exclusion: {exclude_outliers})...\")\n",
    "    for c1_stat_main, c2_stat_main in tqdm(comparison_pairs_final_list, desc=\"Comparing Pairs\", unit=\"pair\"):\n",
    "        all_comparison_results_dict[(c1_stat_main, c2_stat_main)] = {}\n",
    "        \n",
    "        # For each microstate (A, B, C, D)\n",
    "        for ms_idx_stat_main in range(4):\n",
    "            # Get raw and z-score data for both conditions\n",
    "            m1r_stat = get_data_for_stat_testing_internal(c1_stat_main, ms_idx_stat_main, 'map')\n",
    "            m2r_stat = get_data_for_stat_testing_internal(c2_stat_main, ms_idx_stat_main, 'map')\n",
    "            m1z_stat = get_data_for_stat_testing_internal(c1_stat_main, ms_idx_stat_main, 'zmap')\n",
    "            m2z_stat = get_data_for_stat_testing_internal(c2_stat_main, ms_idx_stat_main, 'zmap')\n",
    "            \n",
    "            # Store subject counts for this microstate comparison\n",
    "            current_ms_res_dict = {'n_raw':(m1r_stat.shape[0],m2r_stat.shape[0]), 'n_z':(m1z_stat.shape[0],m2z_stat.shape[0])}\n",
    "            \n",
    "            # Process both raw and z-score data\n",
    "            for d_type_stat, d1_stat_arr, d2_stat_arr, n1_stat_val, n2_stat_val, pfx_stat in [\n",
    "                ('raw', m1r_stat, m2r_stat, m1r_stat.shape[0], m2r_stat.shape[0], 'raw_'),\n",
    "                ('z',   m1z_stat, m2z_stat, m1z_stat.shape[0], m2z_stat.shape[0], 'z_')]:\n",
    "                \n",
    "                # Initialize arrays for statistical results\n",
    "                p_stat_arr = np.full(n_channels_final, np.nan)\n",
    "                md_stat_arr = np.full(n_channels_final, np.nan)\n",
    "                t_stat_arr = np.full(n_channels_final, np.nan)\n",
    "                d_stat_arr = np.full(n_channels_final, np.nan)\n",
    "                \n",
    "                # Perform channel-wise statistical tests if enough subjects in both groups\n",
    "                if n1_stat_val >= 2 and n2_stat_val >= 2:\n",
    "                    for ch_i_stat in range(n_channels_final):\n",
    "                        # Get channel data for both conditions\n",
    "                        d1ch_stat, d2ch_stat = d1_stat_arr[:, ch_i_stat], d2_stat_arr[:, ch_i_stat]\n",
    "                        \n",
    "                        # Check for valid variance in both groups\n",
    "                        var1_ok_stat = np.nanvar(d1ch_stat) > 1e-10\n",
    "                        var2_ok_stat = np.nanvar(d2ch_stat) > 1e-10\n",
    "                        \n",
    "                        if var1_ok_stat and var2_ok_stat:\n",
    "                            try:\n",
    "                                # Perform t-test and calculate effect size (Cohen's d)\n",
    "                                t_s_val, p_s_val = ttest_ind(d1ch_stat, d2ch_stat, equal_var=False, nan_policy='omit')\n",
    "                                c_d_val = cohen_d(d1ch_stat[~np.isnan(d1ch_stat)], d2ch_stat[~np.isnan(d2ch_stat)])\n",
    "                                \n",
    "                                # Store results\n",
    "                                md_stat_arr[ch_i_stat] = np.nanmean(d1ch_stat) - np.nanmean(d2ch_stat)\n",
    "                                t_stat_arr[ch_i_stat] = t_s_val\n",
    "                                p_stat_arr[ch_i_stat] = p_s_val\n",
    "                                d_stat_arr[ch_i_stat] = c_d_val\n",
    "                            except Exception as e_stat_calc_loop: \n",
    "                                print(f\" Stat Err({pfx_stat}MS{ms_idx_stat_main},Ch{ch_i_stat}):{e_stat_calc_loop}\")\n",
    "                        elif n1_stat_val > 0 and n2_stat_val > 0: \n",
    "                            # If variance check fails but both groups have subjects, just calculate mean difference\n",
    "                            md_stat_arr[ch_i_stat] = np.nanmean(d1ch_stat) - np.nanmean(d2ch_stat)\n",
    "                elif n1_stat_val > 0 and n2_stat_val > 0:\n",
    "                    # If not enough subjects for t-test, just calculate mean differences\n",
    "                    for ch_i_stat in range(n_channels_final): \n",
    "                        md_stat_arr[ch_i_stat] = np.nanmean(d1_stat_arr[:, ch_i_stat]) - np.nanmean(d2_stat_arr[:, ch_i_stat])\n",
    "                \n",
    "                # Store results in dictionary\n",
    "                current_ms_res_dict[f'{pfx_stat}p_values'] = p_stat_arr\n",
    "                current_ms_res_dict[f'{pfx_stat}mean_diffs'] = md_stat_arr\n",
    "                current_ms_res_dict[f'{pfx_stat}t_scores'] = t_stat_arr\n",
    "                current_ms_res_dict[f'{pfx_stat}cohen_d'] = d_stat_arr\n",
    "                current_ms_res_dict[f'{pfx_stat}significant_channel'] = np.zeros(n_channels_final, dtype=bool)\n",
    "                current_ms_res_dict[f'{pfx_stat}n_significant_channel'] = 0\n",
    "                \n",
    "            # Store results for this microstate\n",
    "            all_comparison_results_dict[(c1_stat_main, c2_stat_main)][ms_idx_stat_main] = current_ms_res_dict\n",
    "\n",
    "    # Apply FDR (False Discovery Rate) correction for multiple comparisons\n",
    "    print(f\"\\nApplying FDR correction...\")\n",
    "    if all_comparison_results_dict:\n",
    "        for pair_key_fdr_main, ms_results_fdr_main in all_comparison_results_dict.items():\n",
    "            for ms_idx_fdr_main, res_data_fdr_main in ms_results_fdr_main.items():\n",
    "                for prefix_fdr_main in ['raw_', 'z_']:\n",
    "                    # Get p-values for this microstate and map type\n",
    "                    p_values_fdr_main = res_data_fdr_main.get(f'{prefix_fdr_main}p_values', [])\n",
    "                    \n",
    "                    # Find valid (non-NaN) p-values\n",
    "                    valid_p_indices_fdr = ~np.isnan(p_values_fdr_main)\n",
    "                    p_values_to_correct_fdr = p_values_fdr_main[valid_p_indices_fdr]\n",
    "                    \n",
    "                    if len(p_values_to_correct_fdr) > 0:\n",
    "                        # Apply Benjamini-Hochberg FDR correction\n",
    "                        reject_fdr_arr, _, _, _ = multipletests(p_values_to_correct_fdr, 0.05, 'fdr_bh')\n",
    "                        \n",
    "                        # Store which channels are significant after correction\n",
    "                        res_data_fdr_main[f'{prefix_fdr_main}significant_channel'][valid_p_indices_fdr] = reject_fdr_arr\n",
    "                        res_data_fdr_main[f'{prefix_fdr_main}n_significant_channel'] = np.sum(reject_fdr_arr)\n",
    "    else:\n",
    "        print(\"No comparison results to apply FDR correction to.\")\n",
    "\n",
    "    # Generate visualizations if electrode coordinates are available\n",
    "    if p2d_normalized_coords is not None:\n",
    "        print(\"\\nGenerating visualizations...\")\n",
    "        ordered_ms_indices_for_plot = [0, 1, 2, 3]  # A, B, C, D\n",
    "        \n",
    "        # For each comparison pair\n",
    "        for (c1_p, c2_p), results_for_pair_p in all_comparison_results_dict.items():\n",
    "            print(f\"  Generating plots for {c1_p} vs {c2_p}...\")\n",
    "            \n",
    "            # Create output directory for this comparison\n",
    "            output_dir_for_pair_p = os.path.join(output_base_analysis, f'{c1_p}_vs_{c2_p}')\n",
    "            os.makedirs(output_dir_for_pair_p, exist_ok=True)\n",
    "            \n",
    "            # Set global plotting parameters\n",
    "            glob_t_max_p = 5.0\n",
    "            glob_t_min_p = -glob_t_max_p\n",
    "            glob_d_min_s_p = 0.0\n",
    "            glob_d_max_s_p = 1.0\n",
    "            min_m_area_p = 50\n",
    "            max_m_area_p = 600\n",
    "            \n",
    "            # Generate plots for both raw potentials and z-scores\n",
    "            for plot_var, data_pfx_p, fig_title_sfx_p in [\n",
    "                ('potential', 'raw_', \"\"), ('zscore', 'z_', \" (Z-Score Data)\")]:\n",
    "                \n",
    "                # Create figure with 4 subplots (one for each microstate)\n",
    "                fig_p_main = plt.figure(figsize=(16, 5.5))\n",
    "                gs_p_main = gridspec.GridSpec(1, 4, figure=fig_p_main, hspace=0.3, wspace=0.1, top=0.88, bottom=0.12, left=0.05, right=0.80)\n",
    "                sc_handles_p = {}\n",
    "                \n",
    "                # Plot each microstate\n",
    "                for i_plot_c, ms_idx_p_ord in enumerate(ordered_ms_indices_for_plot):\n",
    "                    if ms_idx_p_ord not in results_for_pair_p: \n",
    "                        continue\n",
    "                    \n",
    "                    # Get results for this microstate\n",
    "                    ms_res_p = results_for_pair_p[ms_idx_p_ord]\n",
    "                    \n",
    "                    # Create subplot and draw head schematic\n",
    "                    ax_p = fig_p_main.add_subplot(gs_p_main[0, i_plot_c])\n",
    "                    draw_head(ax_p)\n",
    "                    \n",
    "                    # Get t-scores, p-values and effect sizes for plotting\n",
    "                    t_sc_p = ms_res_p[f'{data_pfx_p}t_scores']\n",
    "                    p_val_p_mask = ms_res_p[f'{data_pfx_p}p_values']\n",
    "                    coh_d_p_size = np.abs(ms_res_p[f'{data_pfx_p}cohen_d'])\n",
    "                    \n",
    "                    # Create mask for significant channels (p < 0.05)\n",
    "                    plot_s_mask = (~np.isnan(p_val_p_mask)) & (p_val_p_mask < 0.05)\n",
    "                    \n",
    "                    # Plot channel values: t-scores as colors, effect sizes as circle sizes\n",
    "                    sc_h_p_val = plot_channel_values(\n",
    "                        ax_p, p2d_normalized_coords, t_sc_p, 'RdBu_r', glob_t_min_p, glob_t_max_p,\n",
    "                        sig_mask=plot_s_mask, size_values=coh_d_p_size, size_vmin=glob_d_min_s_p, size_vmax=glob_d_max_s_p,\n",
    "                        min_marker_size=min_m_area_p, max_marker_size=max_m_area_p\n",
    "                    )\n",
    "                    \n",
    "                    # Set microstate label as subplot title\n",
    "                    ax_p.set_title(ms_labels[ms_idx_p_ord], fontsize=14)\n",
    "                    \n",
    "                    # Store scatter handle for colorbar\n",
    "                    if i_plot_c == 0 and sc_h_p_val is not None:\n",
    "                        sc_handles_p['t_stat'] = sc_h_p_val\n",
    "                \n",
    "                # Add colorbar for t-statistics\n",
    "                if 't_stat' in sc_handles_p:\n",
    "                    cax_t_p_main = fig_p_main.add_axes([0.83, 0.15, 0.015, 0.7])\n",
    "                    cb_t_p_main = fig_p_main.colorbar(sc_handles_p['t_stat'], cax=cax_t_p_main)\n",
    "                    cb_t_p_main.set_label('T-Statistic', size=14)\n",
    "                \n",
    "                # Create a separate axis for the continuous cone-shaped legend\n",
    "                s_range_leg_p = glob_d_max_s_p - glob_d_min_s_p\n",
    "                s_range_leg_p = 1.0 if s_range_leg_p <= 1e-9 else s_range_leg_p\n",
    "                \n",
    "                # Create a separate axis for the continuous cone-shaped legend\n",
    "                cone_ax = fig_p_main.add_axes([0.9, 0.2, 0.08, 0.6])  # Positioned further right\n",
    "                cone_ax.set_xlim(0, 1)\n",
    "                cone_ax.set_ylim(0, 1)\n",
    "                \n",
    "                # Create a continuous cone shape\n",
    "                num_points = 100  # Number of points for smoother cone\n",
    "                y_vals = np.linspace(0, 1, num_points)\n",
    "                x_center = 0.5\n",
    "                max_radius = 0.3  # Cone width at base\n",
    "                \n",
    "                # Calculate d values along the cone\n",
    "                d_vals = np.linspace(glob_d_min_s_p, glob_d_max_s_p, num_points)\n",
    "                \n",
    "                # Calculate marker sizes that would be used in the actual plot\n",
    "                norm_d_vals = np.clip((d_vals - glob_d_min_s_p) / s_range_leg_p, 0, 1)\n",
    "                marker_sizes = min_m_area_p + (max_m_area_p - min_m_area_p) * norm_d_vals\n",
    "                \n",
    "                # Scale marker sizes for the legend\n",
    "                scaled_radii = np.sqrt(marker_sizes / np.pi) / 100  # Scale to fit in the axis\n",
    "                \n",
    "                # Draw the cone shape points (circles)\n",
    "                for i, (y, r) in enumerate(zip(y_vals, scaled_radii)):\n",
    "                    circle = plt.Circle((x_center, y), r, facecolor='grey', edgecolor='k', lw=0.5)\n",
    "                    cone_ax.add_patch(circle)\n",
    "                \n",
    "                # Set tick and label offsets\n",
    "                tick_offset = 0.15  # Increased offset\n",
    "                label_offset = 0.25  # Increased offset\n",
    "                \n",
    "                # Draw vertical axis line\n",
    "                cone_ax.plot([x_center, x_center], [0, 1], 'k-', lw=0.75)\n",
    "                \n",
    "                # Add markers and labels for specific d values\n",
    "                d_markers = [0.0, 0.2, 0.4, 0.6, 0.8, 1.0]  # More markers for better reference\n",
    "                for d in d_markers:\n",
    "                    # Find the position on y-axis corresponding to this d value\n",
    "                    y_pos = (d - glob_d_min_s_p) / (glob_d_max_s_p - glob_d_min_s_p) if glob_d_max_s_p != glob_d_min_s_p else 0.5\n",
    "                    if 0 <= y_pos <= 1:  # Ensure it's within the axis bounds\n",
    "                        # Draw tick mark with offset\n",
    "                        cone_ax.plot([x_center - tick_offset, x_center], [y_pos, y_pos], 'k-', lw=0.5)\n",
    "                        # Label with offset\n",
    "                        cone_ax.text(x_center - label_offset, y_pos, f\"{d:.1f}\", ha='right', va='center', fontsize=14)\n",
    "                \n",
    "                cone_ax.set_title(\"abs(Cohen's d)\", fontsize=14, pad=10)\n",
    "                cone_ax.axis('off')  # Hide the axis lines but keep the content\n",
    "                \n",
    "                # Set figure title and save\n",
    "                fig_p_main.suptitle(f'{c1_p} vs {c2_p}{fig_title_sfx_p}', fontsize=16, y=0.96)\n",
    "                plot_fname_p = os.path.join(output_dir_for_pair_p, f'comparison_{plot_var}_fdr_tTest_cohenDsize{output_suffix}.png')\n",
    "                fig_p_main.savefig(plot_fname_p, dpi=300, bbox_inches='tight')\n",
    "                plt.close(fig_p_main)\n",
    "            \n",
    "            print(f\"    Visualizations saved for {c1_p} vs {c2_p}.\")\n",
    "    else:\n",
    "        print(\"\\nSkipping visualizations: Normalized 2D electrode coordinates not available.\")\n",
    "\n",
    "    # Save numerical results to CSV files\n",
    "    print(\"\\nSaving numerical results (CSVs)...\")\n",
    "    try:\n",
    "        # For each comparison pair\n",
    "        for (c1_csv_main, c2_csv_main), res_pair_data_csv_main in all_comparison_results_dict.items():\n",
    "            # Create output directory for this comparison\n",
    "            out_dir_csv_p_main = os.path.join(output_base_analysis, f'{c1_csv_main}_vs_{c2_csv_main}')\n",
    "            os.makedirs(out_dir_csv_p_main, exist_ok=True)\n",
    "            \n",
    "            # For each microstate in this comparison\n",
    "            for ms_idx_val_csv_main, ms_res_data_csv_main in res_pair_data_csv_main.items():\n",
    "                ms_l_csv_main = ms_labels.get(ms_idx_val_csv_main, f'MS{ms_idx_val_csv_main}')\n",
    "                \n",
    "                # Save both raw and z-score results\n",
    "                for pfx_csv_main in ['raw_', 'z_']:\n",
    "                    # Create DataFrame with all statistical results\n",
    "                    df_cols_csv_main = {\n",
    "                        'Channel': master_channel_names,\n",
    "                        f'MeanDiff_uV' if pfx_csv_main == 'raw_' else 'MeanDiff_Z': ms_res_data_csv_main[f'{pfx_csv_main}mean_diffs'],\n",
    "                        'T_Statistic': ms_res_data_csv_main[f'{pfx_csv_main}t_scores'], \n",
    "                        'Cohen_d': ms_res_data_csv_main[f'{pfx_csv_main}cohen_d'],\n",
    "                        'p_Value_uncorrected': ms_res_data_csv_main[f'{pfx_csv_main}p_values'],\n",
    "                        'Significant_FDR_BH': ms_res_data_csv_main[f'{pfx_csv_main}significant_channel']\n",
    "                    }\n",
    "                    df_out_csv_main = pd.DataFrame(df_cols_csv_main)\n",
    "                    \n",
    "                    # Save to CSV file\n",
    "                    csv_fpath_main = os.path.join(\n",
    "                        out_dir_csv_p_main, \n",
    "                        f'MS{ms_l_csv_main}_{pfx_csv_main[:-1]}_results_{c1_csv_main}_vs_{c2_csv_main}_fdr_per_ms{output_suffix}.csv'\n",
    "                    )\n",
    "                    df_out_csv_main.to_csv(csv_fpath_main, index=False, float_format='%.6f', na_rep='NaN')\n",
    "        \n",
    "        print(\"  CSV files saved.\")\n",
    "    except Exception as e_save_csv_main:\n",
    "        print(f\"  Error saving CSV files: {e_save_csv_main}\")\n",
    "\n",
    "    # Generate and save summary report\n",
    "    print(\"\\nGenerating summary report...\")\n",
    "    report_fpath_main = os.path.join(output_base_analysis, f'summary_report_fdr_per_ms{output_suffix}.txt')\n",
    "    try:\n",
    "        with open(report_fpath_main, 'w', encoding='utf-8') as fr_main:\n",
    "            # Write report header\n",
    "            fr_main.write(\"MICROSTATE COMPARISON SUMMARY REPORT\\n\" + \"=\"*40 + \"\\n\\n\")\n",
    "            fr_main.write(f\"Analysis Output Dir: {os.path.abspath(output_base_analysis)}\\nRef Cond: {ref_name_key_main}\\n\")\n",
    "            fr_main.write(f\"All Processed Conds: {list(condition_data_store.keys())}\\nComparison Pairs: {comparison_pairs_final_list}\\n\")\n",
    "            fr_main.write(f\"Outlier Exclusion: {exclude_outliers} (MS-Wise if True)\\n\\nInitial Subject Counts (before MS-specific exclusion for stats):\\n\")\n",
    "            \n",
    "            # Write subject counts for each condition\n",
    "            for ck_rpi, cts_rpi in initial_subject_counts_dict.items():\n",
    "                fr_main.write(f\"  - {ck_rpi}: Files Found={cts_rpi['found_files']}, Subjects Loaded={cts_rpi['loaded_subjects']}\\n\")\n",
    "            \n",
    "            # Write FDR information\n",
    "            fr_main.write(\"\\nFDR (Benjamini/Hochberg, alpha=0.05) applied PER MICROSTATE across channels.\\n\" + \"-\"*75 + \"\\n\\n\")\n",
    "            \n",
    "            if not all_comparison_results_dict:\n",
    "                fr_main.write(\"No comparison results generated.\\n\")\n",
    "            else:\n",
    "                # For each comparison pair\n",
    "                for (c1_rm, c2_rm), data_for_rp_pair_m in all_comparison_results_dict.items():\n",
    "                    # Write comparison header\n",
    "                    fr_main.write(f\"Comparison: {c1_rm} vs {c2_rm}\\n\" + \"=\"*len(f\"Comparison: {c1_rm} vs {c2_rm}\") + \"\\n\\n\")\n",
    "                    fr_main.write(\"Sig. Channels (FDR p<0.05) & N subjects per MS in T-test:\\n\")\n",
    "                    fr_main.write(\"---------------------------------------------------------------------------\\n\")\n",
    "                    fr_main.write(\"| Microstate | N (Raw: c1/c2) | N (Z-Sc: c1/c2) | Sig. Ch Raw | Sig. Ch Z |\\n\")\n",
    "                    fr_main.write(\"|------------|----------------|-----------------|-------------|-----------|\\n\")\n",
    "                    \n",
    "                    any_s_p_m = False\n",
    "                    # For each microstate in this comparison\n",
    "                    for ms_idx_rm in range(4):\n",
    "                        ms_l_rm = ms_labels.get(ms_idx_rm, f'MS{ms_idx_rm}')\n",
    "                        ms_res_rm = data_for_rp_pair_m.get(ms_idx_rm, {})\n",
    "                        \n",
    "                        # Get subject counts\n",
    "                        n_r_v_rm = ms_res_rm.get('n_raw', ('?', '?'))\n",
    "                        n_z_v_rm = ms_res_rm.get('n_z', ('?', '?'))\n",
    "                        n_r_s_rm = f\"{n_r_v_rm[0]}/{n_r_v_rm[1]}\"\n",
    "                        n_z_s_rm = f\"{n_z_v_rm[0]}/{n_z_v_rm[1]}\"\n",
    "                        \n",
    "                        # Get significant channel counts\n",
    "                        n_s_r_val = ms_res_rm.get('raw_n_significant_channel', 0)\n",
    "                        n_s_z_val = ms_res_rm.get('z_n_significant_channel', 0)\n",
    "                        \n",
    "                        # Write table row\n",
    "                        fr_main.write(f\"| {ms_l_rm:<10} | {n_r_s_rm:<14} | {n_z_s_rm:<15} | {n_s_r_val:<11} | {n_s_z_val:<9} |\\n\")\n",
    "                        \n",
    "                        if n_s_r_val > 0 or n_s_z_val > 0:\n",
    "                            any_s_p_m = True\n",
    "                    \n",
    "                    fr_main.write(\"---------------------------------------------------------------------------\\n\")\n",
    "                    if not any_s_p_m:\n",
    "                        fr_main.write(\"  (No FDR significant channels for this pair)\\n\")\n",
    "                    fr_main.write(\"\\n\" + \"-\"*40 + \"\\n\\n\")\n",
    "        \n",
    "        print(f\"Summary report saved to: {report_fpath_main}\")\n",
    "    except Exception as e_write_rep_main:\n",
    "        print(f\"Error generating summary report: {e_write_rep_main}\")\n",
    "\n",
    "    print(f\"\\nAnalysis complete. Results in: {os.path.abspath(output_base_analysis)}\")\n",
    "    return all_comparison_results_dict\n",
    "\n",
    "# Function calls to run the topographic analyses with and without outliers\n",
    "## Process the older HC group comparing topographies between sleep stages (e.g., N2 vs REM)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Function call with outlier exclusion\n",
    "    results_no_outliers = compare_median_microstates_across_conditions(\n",
    "        ref_path='./median_microstates_and_outliers/HC_Awake_median',\n",
    "        other_paths={\n",
    "            'HC_N2': './median_microstates_and_outliers/HC_N2_median',\n",
    "            'HC_REM': './median_microstates_and_outliers/HC_REM_median'\n",
    "        },\n",
    "        output_base='./microstate_analysis_output_newplots4/comparison_results',\n",
    "        xyz_file='Electrodes 10-20_v3.20.xyz',\n",
    "        exclude_outliers=True,\n",
    "        outlier_subjects=outliers,  # Now passing outlier_subjects instead of non_outlier_subjects\n",
    "        output_suffix='_no_outliers'\n",
    "    )\n",
    "    \n",
    "    # Function call with all subjects (no outlier exclusion)\n",
    "    results_all = compare_median_microstates_across_conditions(\n",
    "        ref_path='./median_microstates_and_outliers/HC_Awake_median',\n",
    "        other_paths={\n",
    "            'HC_N2': './median_microstates_and_outliers/HC_N2_median',\n",
    "            'HC_REM': './median_microstates_and_outliers/HC_REM_median'\n",
    "        },\n",
    "        output_base='./microstate_analysis_output_newplots4/comparison_older_results',\n",
    "        xyz_file='Electrodes 10-20_v3.20.xyz',\n",
    "        exclude_outliers=False,\n",
    "        outlier_subjects=None,\n",
    "        output_suffix=''\n",
    "    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c04871-d3e3-4bc5-8585-79c28902566b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Process the older HC group comparing topographies between sleep stages (e.g., N2 vs REM)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Function call with outlier exclusion\n",
    "    results_no_outliers = compare_median_microstates_across_conditions(\n",
    "        ref_path='./median_microstates_and_outliers/Young_Awake_median',\n",
    "        other_paths={\n",
    "            'HC_N2': './median_microstates_and_outliers/Young_N2_median',\n",
    "            'HC_REM': './median_microstates_and_outliers/Young_REM_median'\n",
    "        },\n",
    "        output_base='./microstate_analysis_output_newplots4/comparison_younger_results',\n",
    "        xyz_file='Electrodes 10-20_v3.20.xyz',\n",
    "        exclude_outliers=True,\n",
    "        outlier_subjects=outliers,  # Now passing outlier_subjects instead of non_outlier_subjects\n",
    "        output_suffix='_no_outliers'\n",
    "    )\n",
    "    \n",
    "    # Function call with all subjects (no outlier exclusion)\n",
    "    results_all = compare_median_microstates_across_conditions(\n",
    "        ref_path='./median_microstates_and_outliers/Young_Awake_median',\n",
    "        other_paths={\n",
    "            'HC_N2': './median_microstates_and_outliers/Young_N2_median',\n",
    "            'HC_REM': './median_microstates_and_outliers/Young_REM_median'\n",
    "        },\n",
    "        output_base='./microstate_analysis_output_newplots4/comparison_younger_results',\n",
    "        xyz_file='Electrodes 10-20_v3.20.xyz',\n",
    "        exclude_outliers=False,\n",
    "        outlier_subjects=None,\n",
    "        output_suffix=''\n",
    "    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8425f807-7fd8-4083-95d0-d8d59b06f157",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compare the older HC group vs Younger HC group across sleep stages\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Function call with outlier exclusion\n",
    "    results_no_outliers = compare_median_microstates_across_conditions(\n",
    "        ref_path='./median_microstates_and_outliers/HC_Awake_median',\n",
    "        other_paths={\n",
    "            'Young_Awake': './median_microstates_and_outliers/Young_Awake_median'\n",
    "        },\n",
    "        output_base='./microstate_analysis_output_newplots4/Old_vs_young',\n",
    "        xyz_file='Electrodes 10-20_v3.20.xyz',\n",
    "        exclude_outliers=True,\n",
    "        outlier_subjects=outliers,  # Now passing outlier_subjects instead of non_outlier_subjects\n",
    "        output_suffix='_no_outliers'\n",
    "    )\n",
    "    \n",
    "    # Function call with all subjects (no outlier exclusion)\n",
    "    results_all = compare_median_microstates_across_conditions(\n",
    "        ref_path='./median_microstates_and_outliers/HC_Awake_median',\n",
    "        other_paths={\n",
    "            'Young_Awake': './median_microstates_and_outliers/Young_Awake_median'\n",
    "        },\n",
    "        output_base='./microstate_analysis_output_newplots4/Old_vs_young',\n",
    "        xyz_file='Electrodes 10-20_v3.20.xyz',\n",
    "        exclude_outliers=False,\n",
    "        outlier_subjects=None,\n",
    "        output_suffix=''\n",
    "    ) \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Function call with outlier exclusion\n",
    "    results_no_outliers = compare_median_microstates_across_conditions(\n",
    "        ref_path='./median_microstates_and_outliers/HC_N2_median',\n",
    "        other_paths={\n",
    "            'Young_N2': './median_microstates_and_outliers/Young_N2_median'\n",
    "        },\n",
    "        output_base='./microstate_analysis_output_newplots4/Old_vs_young',\n",
    "        xyz_file='Electrodes 10-20_v3.20.xyz',\n",
    "        exclude_outliers=True,\n",
    "        outlier_subjects=outliers,  # Now passing outlier_subjects instead of non_outlier_subjects\n",
    "        output_suffix='_no_outliers'\n",
    "    )\n",
    "    \n",
    "    # Function call with all subjects (no outlier exclusion)\n",
    "    results_all = compare_median_microstates_across_conditions(\n",
    "        ref_path='./median_microstates_and_outliers/HC_N2_median',\n",
    "        other_paths={\n",
    "            'Young_N2': './median_microstates_and_outliers/Young_N2_median'\n",
    "        },\n",
    "        output_base='./microstate_analysis_output_newplots4/Old_vs_young',\n",
    "        xyz_file='Electrodes 10-20_v3.20.xyz',\n",
    "        exclude_outliers=False,\n",
    "        outlier_subjects=None,\n",
    "        output_suffix=''\n",
    "    ) \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Function call with outlier exclusion\n",
    "    results_no_outliers = compare_median_microstates_across_conditions(\n",
    "        ref_path='./median_microstates_and_outliers/HC_REM_median',\n",
    "        other_paths={\n",
    "            'Young_REM': './median_microstates_and_outliers/Young_REM_median'\n",
    "        },\n",
    "        output_base='./microstate_analysis_output_newplots4/Old_vs_young',\n",
    "        xyz_file='Electrodes 10-20_v3.20.xyz',\n",
    "        exclude_outliers=True,\n",
    "        outlier_subjects=outliers,  # Now passing outlier_subjects instead of non_outlier_subjects\n",
    "        output_suffix='_no_outliers'\n",
    "    )\n",
    "    \n",
    "    # Function call with all subjects (no outlier exclusion)\n",
    "    results_all = compare_median_microstates_across_conditions(\n",
    "        ref_path='./median_microstates_and_outliers/HC_REM_median',\n",
    "        other_paths={\n",
    "            'Young_REM': './median_microstates_and_outliers/Young_REM_median'\n",
    "        },\n",
    "        output_base='./microstate_analysis_output_newplots4/Old_vs_young',\n",
    "        xyz_file='Electrodes 10-20_v3.20.xyz',\n",
    "        exclude_outliers=False,\n",
    "        outlier_subjects=None,\n",
    "        output_suffix=''\n",
    "    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208108ec-529f-49af-b6cb-be4f891c2562",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compare pathological groups\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Function call with outlier exclusion\n",
    "    results_no_outliers = compare_median_microstates_across_conditions(\n",
    "        ref_path='./median_microstates_and_outliers/ADNoEp_Awake_median',\n",
    "        other_paths={\n",
    "            'ADEp_Awake': './median_microstates_and_outliers/ADEp_Awake_median',\n",
    "            'HC_Awake': './median_microstates_and_outliers/HC_Awake_median'\n",
    "        },\n",
    "        output_base='./microstate_analysis_output_newplots4/pathological_results',\n",
    "        xyz_file='Electrodes 10-20_v3.20.xyz',\n",
    "        exclude_outliers=True,\n",
    "        outlier_subjects=outliers,  # Now passing outlier_subjects instead of non_outlier_subjects\n",
    "        output_suffix='_no_outliers'\n",
    "    )\n",
    "    \n",
    "    # Function call with all subjects (no outlier exclusion)\n",
    "    results_all = compare_median_microstates_across_conditions(\n",
    "        ref_path='./median_microstates_and_outliers/ADNoEp_Awake_median',\n",
    "        other_paths={\n",
    "            'ADEp_Awake': './median_microstates_and_outliers/ADEp_Awake_median',\n",
    "            'HC_Awake': './median_microstates_and_outliers/HC_Awake_median'\n",
    "        },\n",
    "        output_base='./microstate_analysis_output_newplots4/pathological_results',\n",
    "        xyz_file='Electrodes 10-20_v3.20.xyz',\n",
    "        exclude_outliers=False,\n",
    "        outlier_subjects=None,\n",
    "        output_suffix=''\n",
    "    ) \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Function call with outlier exclusion\n",
    "    results_no_outliers = compare_median_microstates_across_conditions(\n",
    "        ref_path='./median_microstates_and_outliers/ADNoEp_N2_median',\n",
    "        other_paths={\n",
    "            'ADEp_N2': './median_microstates_and_outliers/ADEp_N2_median',\n",
    "            'HC_N2': './median_microstates_and_outliers/HC_N2_median'\n",
    "        },\n",
    "        output_base='./microstate_analysis_output_newplots4/pathological_results',\n",
    "        xyz_file='Electrodes 10-20_v3.20.xyz',\n",
    "        exclude_outliers=True,\n",
    "        outlier_subjects=outliers,  # Now passing outlier_subjects instead of non_outlier_subjects\n",
    "        output_suffix='_no_outliers'\n",
    "    )\n",
    "    \n",
    "    # Function call with all subjects (no outlier exclusion)\n",
    "    results_all = compare_median_microstates_across_conditions(\n",
    "        ref_path='./median_microstates_and_outliers/ADNoEp_N2_median',\n",
    "        other_paths={\n",
    "            'ADEp_N2': './median_microstates_and_outliers/ADEp_N2_median',\n",
    "            'HC_N2': './median_microstates_and_outliers/HC_N2_median'\n",
    "        },\n",
    "        output_base='./microstate_analysis_output_newplots4/pathological_results',\n",
    "        xyz_file='Electrodes 10-20_v3.20.xyz',\n",
    "        exclude_outliers=False,\n",
    "        outlier_subjects=None,\n",
    "        output_suffix=''\n",
    "    ) \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Function call with outlier exclusion\n",
    "    results_no_outliers = compare_median_microstates_across_conditions(\n",
    "        ref_path='./median_microstates_and_outliers/ADNoEp_REM_median',\n",
    "        other_paths={\n",
    "            'ADEp_REM': './median_microstates_and_outliers/ADEp_REM_median',\n",
    "            'HC_REM': './median_microstates_and_outliers/HC_REM_median'\n",
    "        },\n",
    "        output_base='./microstate_analysis_output_newplots4/pathological_results',\n",
    "        xyz_file='Electrodes 10-20_v3.20.xyz',\n",
    "        exclude_outliers=True,\n",
    "        outlier_subjects=outliers,  # Now passing outlier_subjects instead of non_outlier_subjects\n",
    "        output_suffix='_no_outliers'\n",
    "    )\n",
    "    \n",
    "    # Function call with all subjects (no outlier exclusion)\n",
    "    results_all = compare_median_microstates_across_conditions(\n",
    "        ref_path='./median_microstates_and_outliers/ADNoEp_REM_median',\n",
    "        other_paths={\n",
    "            'ADEp_REM': './median_microstates_and_outliers/ADEp_REM_median',\n",
    "            'HC_REM': './median_microstates_and_outliers/HC_REM_median'\n",
    "        },\n",
    "        output_base='./microstate_analysis_output_newplots4/pathological_results',\n",
    "        xyz_file='Electrodes 10-20_v3.20.xyz',\n",
    "        exclude_outliers=False,\n",
    "        outlier_subjects=None,\n",
    "        output_suffix=''\n",
    "    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9af986-c45e-4242-97f1-baaa3f093a10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33221a82-c558-47e3-b8b6-17928706dd65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3032686-8d34-49f1-9c58-df4e81273eab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
